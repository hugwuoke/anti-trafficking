{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee7d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.impute import KNNImputer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b15832",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dc471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reduced CSV with 99% rows removed per group to Data/CTDC data/CTDC_default_filled_one_hot_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/z0msnbbj10vdbs6czbvpsmy40000gn/T/ipykernel_97531/32206527.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_reduced = df_test.groupby('yearOfRegistration', dropna=False, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# ----- PARAMETERS -----\n",
    "remove_percent = 99\n",
    "keep_frac = 1 - remove_percent / 100\n",
    "input_file = \"Data/CTDC data/CTDC_default_filled_one_hot.csv\"\n",
    "output_file = \"Data/CTDC data/CTDC_default_filled_one_hot_test.csv\"\n",
    "\n",
    "# ----- READ CSV -----\n",
    "df_test = pd.read_csv(input_file)\n",
    "\n",
    "# ----- GROUPING AND SAMPLING -----\n",
    "# Group by 'yearOfRegistration'\n",
    "df_reduced = df_test.groupby('yearOfRegistration', dropna=False, group_keys=False).apply(\n",
    "    lambda group: group.sample(frac=keep_frac, random_state=42)\n",
    ")\n",
    "\n",
    "# ----- SAVE THE RESULT -----\n",
    "df_reduced.to_csv(output_file, index=False)\n",
    "print(f\"Saved reduced CSV with {remove_percent}% rows removed per group to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5187c",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"Data/CTDC data/CTDC_default_filled_one_hot.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Define columns to impute (all except \"yearOfRegistration\")\n",
    "cols_to_impute = [col for col in df.columns if col != \"yearOfRegistration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subsamples -> Imputing the full dataset for each k, saving separate CSVs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7160bb99c54c40bf4680f6de110548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k-values:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved imputed dataset for k=3 -> Data/CTDC data/kNN temp/CTDC_kNNavgk3,5,7_impute_k3_test.csv\n",
      "Saved imputed dataset for k=5 -> Data/CTDC data/kNN temp/CTDC_kNNavgk3,5,7_impute_k5_test.csv\n",
      "Saved imputed dataset for k=7 -> Data/CTDC data/kNN temp/CTDC_kNNavgk3,5,7_impute_k7_test.csv\n",
      "Saved final binary argmax thresholded imputed dataset -> Data/CTDC data/CTDC_kNNavg0k3,5,7_impute_final_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Number of subsamples & k-values\n",
    "n_subsamples = 0  # set to 0 for no subsampling, > 0 for bootstrapping\n",
    "k_values = [3, 5, 7]\n",
    "k_values_str = \",\".join(map(str, k_values))\n",
    "\n",
    "# Templates for saving outputs\n",
    "partial_subsample_template = (\n",
    "    \"Data/CTDC data/kNN temp/CTDC_kNNavg{n_subsamples}k{k_values_str}_impute_sample{i}.csv\"\n",
    ")\n",
    "per_k_template_if_no_subsamples = (\n",
    "    \"Data/CTDC data/kNN temp/CTDC_kNNavgk{k_values_str}_impute_k{k}.csv\"\n",
    ")\n",
    "\n",
    "# Final binary output file after binary argmax thresholding\n",
    "overall_binary_output_file = f\"Data/CTDC data/CTDC_kNNavg{n_subsamples}k{k_values_str}_impute_final.csv\"\n",
    "\n",
    "# ---------------------------\n",
    "# KNN IMPUTATION\n",
    "# ---------------------------\n",
    "if n_subsamples == 0:\n",
    "    # --- NO SUBSAMPLING ---\n",
    "    print(\"No subsamples -> Imputing the full dataset for each k, saving separate CSVs.\")\n",
    "    \n",
    "    # List to hold the imputed arrays for each k\n",
    "    all_imputations = []\n",
    "    \n",
    "    for k in tqdm(k_values, desc=\"k-values\"):\n",
    "        imputer = KNNImputer(n_neighbors=k)\n",
    "        imputer.fit(df[cols_to_impute])\n",
    "        imputed_values = imputer.transform(df[cols_to_impute])\n",
    "        all_imputations.append(imputed_values)\n",
    "        \n",
    "        # Merge imputed columns with the original 'yearOfRegistration'\n",
    "        df_imputed = pd.concat(\n",
    "            [df[[\"yearOfRegistration\"]], \n",
    "             pd.DataFrame(imputed_values, columns=cols_to_impute)],\n",
    "            axis=1\n",
    "        )\n",
    "        df_imputed = df_imputed.sort_values(\"yearOfRegistration\", ascending=False)\n",
    "        \n",
    "        # Save per-k imputed dataset\n",
    "        k_output_file = per_k_template_if_no_subsamples.format(\n",
    "            k_values_str=k_values_str, k=k\n",
    "        )\n",
    "        df_imputed.to_csv(k_output_file, index=False)\n",
    "        print(f\"Saved imputed dataset for k={k} -> {k_output_file}\")\n",
    "\n",
    "    # Overall average across the k values\n",
    "    avg_imputed = np.mean(np.stack(all_imputations, axis=0), axis=0)\n",
    "    df_final = pd.concat(\n",
    "        [df[[\"yearOfRegistration\"]],\n",
    "         pd.DataFrame(avg_imputed, columns=cols_to_impute)],\n",
    "        axis=1\n",
    "    )\n",
    "    df_final = df_final.sort_values(\"yearOfRegistration\", ascending=False)\n",
    "\n",
    "else:\n",
    "    # --- WITH SUBSAMPLING ---\n",
    "    print(f\"Performing {n_subsamples} subsamples (bootstrap) with k-values {k_values_str}.\")\n",
    "    subsample_imputed_list = []\n",
    "\n",
    "    for i in tqdm(range(1, n_subsamples + 1), desc=\"Subsamples\"):\n",
    "        # Stratified subsampling by 'yearOfRegistration'\n",
    "        subsample = df.groupby('yearOfRegistration', dropna=False, group_keys=False).apply(\n",
    "            lambda x: x.sample(frac=1, replace=True)\n",
    "        )\n",
    "        \n",
    "        # For each subsample, collect imputations for every k value\n",
    "        k_imputations = []\n",
    "        for k in tqdm(k_values, desc=f\"Subsample {i} k-values\", leave=False):\n",
    "            imputer = KNNImputer(n_neighbors=k)\n",
    "            imputer.fit(subsample[cols_to_impute])\n",
    "            # Note: Imputation is applied on the full dataset even though imputer was fit on the subsample\n",
    "            imputed_values = imputer.transform(df[cols_to_impute])\n",
    "            k_imputations.append(imputed_values)\n",
    "        \n",
    "        # Average the imputed results for the current subsample across k values\n",
    "        avg_imputed_subsample = np.mean(np.stack(k_imputations, axis=0), axis=0)\n",
    "        df_sub_imputed = pd.concat(\n",
    "            [df[[\"yearOfRegistration\"]],\n",
    "             pd.DataFrame(avg_imputed_subsample, columns=cols_to_impute)],\n",
    "            axis=1\n",
    "        )\n",
    "        df_sub_imputed = df_sub_imputed.sort_values(\"yearOfRegistration\", ascending=False)\n",
    "        \n",
    "        # Save the partial result for the subsample for inspection\n",
    "        subsample_output_file = partial_subsample_template.format(\n",
    "            n_subsamples=n_subsamples, k_values_str=k_values_str, i=i\n",
    "        )\n",
    "        df_sub_imputed.to_csv(subsample_output_file, index=False)\n",
    "        print(f\"Saved partial subsample {i} -> {subsample_output_file}\")\n",
    "        \n",
    "        subsample_imputed_list.append(avg_imputed_subsample)\n",
    "    \n",
    "    # Final overall average across all subsamples\n",
    "    final_avg_imputed_data = np.mean(np.stack(subsample_imputed_list, axis=0), axis=0)\n",
    "    df_final = pd.concat(\n",
    "        [df[[\"yearOfRegistration\"]],\n",
    "         pd.DataFrame(final_avg_imputed_data, columns=cols_to_impute)],\n",
    "        axis=1\n",
    "    )\n",
    "    df_final = df_final.sort_values(\"yearOfRegistration\", ascending=False)\n",
    "\n",
    "# ---------------------------\n",
    "# BINARY ARGMAX THRESHOLDING FOR SELECTED GROUPS\n",
    "# ---------------------------\n",
    "# Define the groups (columns starting with these prefixes will be processed using argmax logic)\n",
    "groups = [\"gender\", \"ageBroad\", \"traffickMonths\", \"citizenship\", \"CountryOfExploitation\"]\n",
    "\n",
    "for group in groups:\n",
    "    # Identify columns for the current group (e.g. \"gender_Man\", \"gender_Woman\", etc.)\n",
    "    group_cols = [col for col in df_final.columns if col.startswith(group + \"_\")]\n",
    "    \n",
    "    # Compute \"prevalence\" as the mode for each column in the group\n",
    "    prevalence = {}\n",
    "    for col in group_cols:\n",
    "        mode_series = df_final[col].mode()\n",
    "        prevalence[col] = mode_series.iloc[0] if not mode_series.empty else 0\n",
    "    \n",
    "    # Function to process one row: select the candidate with the maximum value, \n",
    "    # and if tied, choose the one with the highest (mode) prevalence\n",
    "    def process_row(row):\n",
    "        values = row[group_cols]\n",
    "        if values.isnull().all():\n",
    "            return values\n",
    "        max_val = values.max()\n",
    "        candidates = values[values == max_val].index.tolist()\n",
    "        chosen = max(candidates, key=lambda col: prevalence[col]) if len(candidates) > 1 else candidates[0]\n",
    "        # Create a new Series: set the chosen column to 1 and the rest to 0.\n",
    "        new_vals = pd.Series(0, index=group_cols)\n",
    "        new_vals[chosen] = 1\n",
    "        return new_vals\n",
    "    \n",
    "    df_final[group_cols] = df_final.apply(lambda row: process_row(row), axis=1)\n",
    "\n",
    "# ---------------------------\n",
    "# BINARY THRESHOLDING FOR REMAINING COLUMNS\n",
    "# ---------------------------\n",
    "# Identify all remaining columns (excluding \"yearOfRegistration\" and the processed group columns)\n",
    "remaining_cols = [col for col in df_final.columns \n",
    "                  if col != \"yearOfRegistration\" \n",
    "                  and not any(col.startswith(g + \"_\") for g in groups)]\n",
    "\n",
    "# Process each remaining column individually\n",
    "for col in remaining_cols:\n",
    "    mode_series = df_final[col].mode()\n",
    "    col_mode = mode_series.iloc[0] if not mode_series.empty else 0\n",
    "    def threshold_func(x):\n",
    "        if x < 0.5:\n",
    "            return 0\n",
    "        elif x > 0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return col_mode\n",
    "    df_final[col] = df_final[col].apply(threshold_func)\n",
    "\n",
    "# ---------------------------\n",
    "# SAVE FINAL BINARY OUTPUT\n",
    "# ---------------------------\n",
    "df_final.to_csv(overall_binary_output_file, index=False)\n",
    "print(f\"Saved final binary argmax thresholded imputed dataset -> {overall_binary_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
